{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-04 13:40:37.825280: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 7s 7s/step\n",
      "[[5.0937232e-02 1.8598129e-06 2.5161622e-05 1.8899349e-04 7.2617979e-07\n",
      "  1.0814188e-04 4.4507819e-05 8.9817934e-07 1.3806952e-04 9.7918883e-06\n",
      "  2.4988583e-07 2.6686743e-04 1.3170727e-06 5.9471963e-06 2.3459709e-06\n",
      "  3.3398985e-04 2.2129931e-04 5.7124482e-05 9.7117822e-07 3.9364300e-03\n",
      "  5.5959872e-06 1.3169774e-04 1.9836228e-03 9.4311201e-04 1.8538062e-06\n",
      "  1.1373927e-06 2.4097072e-04 3.0521034e-05 1.1038127e-03 1.6325153e-06\n",
      "  5.3481912e-05 4.9765596e-05 4.1379894e-06 9.3910974e-01 2.0090942e-05\n",
      "  3.6820591e-05]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`decode_predictions` expects a batch of predictions (i.e. a 2D array of shape (samples, 1000)). Found array with shape: (1, 36)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/akhilsp/Desktop/nutricuisine/model.ipynb Cell 1\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/akhilsp/Desktop/nutricuisine/model.ipynb#W0sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m prediction\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/akhilsp/Desktop/nutricuisine/model.ipynb#W0sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Test the function\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/akhilsp/Desktop/nutricuisine/model.ipynb#W0sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m classify(\u001b[39m'\u001b[39;49m\u001b[39m/Users/akhilsp/Desktop/nutricuisine/Tomato.jpg\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32m/Users/akhilsp/Desktop/nutricuisine/model.ipynb Cell 1\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/akhilsp/Desktop/nutricuisine/model.ipynb#W0sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(prediction)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/akhilsp/Desktop/nutricuisine/model.ipynb#W0sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Decode predictions\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/akhilsp/Desktop/nutricuisine/model.ipynb#W0sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m prediction \u001b[39m=\u001b[39m decode_predictions(prediction, top\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/akhilsp/Desktop/nutricuisine/model.ipynb#W0sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mprint\u001b[39m(prediction)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/akhilsp/Desktop/nutricuisine/model.ipynb#W0sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Print the predictions\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/site-packages/keras/applications/mobilenet_v2.py:522\u001b[0m, in \u001b[0;36mdecode_predictions\u001b[0;34m(preds, top)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[39m@keras_export\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mkeras.applications.mobilenet_v2.decode_predictions\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    521\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode_predictions\u001b[39m(preds, top\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m):\n\u001b[0;32m--> 522\u001b[0m   \u001b[39mreturn\u001b[39;00m imagenet_utils\u001b[39m.\u001b[39;49mdecode_predictions(preds, top\u001b[39m=\u001b[39;49mtop)\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/site-packages/keras/applications/imagenet_utils.py:147\u001b[0m, in \u001b[0;36mdecode_predictions\u001b[0;34m(preds, top)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mglobal\u001b[39;00m CLASS_INDEX\n\u001b[1;32m    146\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(preds\u001b[39m.\u001b[39mshape) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m preds\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m1000\u001b[39m:\n\u001b[0;32m--> 147\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m`decode_predictions` expects \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    148\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39ma batch of predictions \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    149\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m(i.e. a 2D array of shape (samples, 1000)). \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    150\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mFound array with shape: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(preds\u001b[39m.\u001b[39mshape))\n\u001b[1;32m    151\u001b[0m \u001b[39mif\u001b[39;00m CLASS_INDEX \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m   fpath \u001b[39m=\u001b[39m data_utils\u001b[39m.\u001b[39mget_file(\n\u001b[1;32m    153\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mimagenet_class_index.json\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    154\u001b[0m       CLASS_INDEX_PATH,\n\u001b[1;32m    155\u001b[0m       cache_subdir\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    156\u001b[0m       file_hash\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mc2c37ea517e94d9795004a39431a14cb\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: `decode_predictions` expects a batch of predictions (i.e. a 2D array of shape (samples, 1000)). Found array with shape: (1, 36)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# import model - FV.h5 file\n",
    "base_model = tf.keras.models.load_model('FV.h5')\n",
    "\n",
    "def classify(img_path):\n",
    "    # Load and preprocess the image\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_preprocessed = preprocess_input(img_array)\n",
    "    \n",
    "    # Make predictions\n",
    "    prediction = base_model.predict(img_preprocessed)\n",
    "    print(prediction)\n",
    "    # Decode predictions\n",
    "    prediction = decode_predictions(prediction, top=3)[0]\n",
    "    print(prediction)\n",
    "    # Print the predictions\n",
    "    for pred in prediction:\n",
    "        print(pred)\n",
    "        print(\"Predicted %s with confidence %.2f%%\" % (pred[1], pred[2]*100))\n",
    "    return prediction\n",
    "\n",
    "# Test the function\n",
    "classify('/Users/akhilsp/Desktop/nutricuisine/Tomato.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 19:47:26.139265: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x28e090040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "[33]\n",
      "tomato\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Tomato'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "# import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('FV.h5')\n",
    "\n",
    "labels = {0: 'apple', 1: 'banana', 2: 'beetroot', 3: 'bell pepper', 4: 'cabbage', 5: 'capsicum', 6: 'carrot',\n",
    "          7: 'cauliflower', 8: 'chilli pepper', 9: 'corn', 10: 'cucumber', 11: 'eggplant', 12: 'garlic', 13: 'ginger',\n",
    "          14: 'grapes', 15: 'jalepeno', 16: 'kiwi', 17: 'lemon', 18: 'lettuce',\n",
    "          19: 'mango', 20: 'onion', 21: 'orange', 22: 'paprika', 23: 'pear', 24: 'peas', 25: 'pineapple',\n",
    "          26: 'pomegranate', 27: 'potato', 28: 'raddish', 29: 'soy beans', 30: 'spinach', 31: 'sweetcorn',\n",
    "          32: 'sweetpotato', 33: 'tomato', 34: 'turnip', 35: 'watermelon'}\n",
    "\n",
    "\n",
    "def prepare_image(img_path):\n",
    "    img = load_img(img_path, target_size=(224, 224, 3))\n",
    "    img = img_to_array(img)\n",
    "    img = img / 255\n",
    "    img = np.expand_dims(img, [0])\n",
    "    answer = model.predict(img)\n",
    "    y_class = answer.argmax(axis=-1)\n",
    "    print(y_class)\n",
    "    y = \" \".join(str(x) for x in y_class)\n",
    "    y = int(y)\n",
    "    res = labels[y]\n",
    "    print(res)\n",
    "    return res.capitalize()\n",
    "\n",
    "def result(img_path):\n",
    "    prediction = prepare_image(img_path)\n",
    "    return prediction\n",
    "    \n",
    "result('/Users/akhilsp/Desktop/nutricuisine/Tomato.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 19:53:59.275763: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 8s 8s/step\n",
      "[33]\n",
      "tomato\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Tomato'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "# import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.models import load_model\n",
    "import json\n",
    "\n",
    "model = load_model('FV.h5')\n",
    "\n",
    "# load labels from labels.json\n",
    "labels = json.load(open('labels.json'))\n",
    "\n",
    "\n",
    "def prepare_image(img_path):\n",
    "    img = load_img(img_path, target_size=(224, 224, 3))\n",
    "    img = img_to_array(img)\n",
    "    img = img / 255\n",
    "    img = np.expand_dims(img, [0])\n",
    "    answer = model.predict(img)\n",
    "    y_class = answer.argmax(axis=-1)\n",
    "    print(y_class)\n",
    "    y = \" \".join(str(x) for x in y_class)\n",
    "    y = int(y)\n",
    "    res = labels[str(y)]\n",
    "    print(res)\n",
    "    return res.capitalize()\n",
    "\n",
    "def result(img_path):\n",
    "    prediction = prepare_image(img_path)\n",
    "    return prediction\n",
    "    \n",
    "result('/Users/akhilsp/Desktop/nutricuisine/Tomato.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 19:55:45.071803: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 8s 8s/step\n",
      "Tomato\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.models import load_model\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Load the model and labels from files\n",
    "def load_model_and_labels(model_path, labels_path):\n",
    "    try:\n",
    "        model = load_model(model_path)\n",
    "        with open(labels_path, 'r') as file:\n",
    "            labels = json.load(file)\n",
    "        return model, labels\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model or labels: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Prepare the image for prediction\n",
    "def prepare_image(img_path, target_size=(224, 224, 3)):\n",
    "    try:\n",
    "        img = load_img(img_path, target_size=target_size)\n",
    "        img = img_to_array(img)\n",
    "        img = img / 255.0\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error preparing image: {e}\")\n",
    "        return None\n",
    "\n",
    "# Predict the class of the image\n",
    "def predict_class(model, img, labels):\n",
    "    try:\n",
    "        prediction = model.predict(img)\n",
    "        y_class = prediction.argmax(axis=-1)\n",
    "        class_id = int(y_class[0])\n",
    "        class_name = labels.get(str(class_id), \"Unknown\")\n",
    "        return class_name.capitalize()\n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction: {e}\")\n",
    "        return \"Prediction error\"\n",
    "\n",
    "# Main function to run the prediction\n",
    "def classify_image(model_path, labels_path, img_path):\n",
    "    model, labels = load_model_and_labels(model_path, labels_path)\n",
    "    if model is None or labels is None:\n",
    "        return \"Model or labels not loaded properly.\"\n",
    "    \n",
    "    img = prepare_image(img_path)\n",
    "    if img is None:\n",
    "        return \"Image not prepared properly.\"\n",
    "    \n",
    "    prediction = predict_class(model, img, labels)\n",
    "    return prediction\n",
    "\n",
    "# Example usage:\n",
    "result = classify_image('FV.h5', 'labels.json', 'Tomato.jpg')\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading model or labels: invalid load key, 'H'.\n",
      "Model or labels not loaded properly.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import json\n",
    "\n",
    "# Load the model and labels from files\n",
    "def load_model_and_labels(model_path, labels_path):\n",
    "    try:\n",
    "        model = torch.load(model_path)\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        with open(labels_path, 'r') as file:\n",
    "            labels = json.load(file)\n",
    "        return model, labels\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model or labels: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Prepare the image for prediction\n",
    "def prepare_image(img_path, target_size=(224, 224)):\n",
    "    try:\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        # Transform the image for the model\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(target_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        img = transform(img).unsqueeze(0)  # Add a batch dimension\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error preparing image: {e}\")\n",
    "        return None\n",
    "\n",
    "# Predict the class of the image\n",
    "def predict_class(model, img, labels):\n",
    "    try:\n",
    "        with torch.no_grad():  # Disable gradient calculation\n",
    "            prediction = model(img)\n",
    "            y_class = prediction.argmax(dim=1)\n",
    "            class_id = int(y_class.item())\n",
    "            class_name = labels.get(str(class_id), \"Unknown\")\n",
    "            return class_name.capitalize()\n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction: {e}\")\n",
    "        return \"Prediction error\"\n",
    "\n",
    "# Main function to run the prediction\n",
    "def classify_image(model_path, labels_path, img_path):\n",
    "    model, labels = load_model_and_labels(model_path, labels_path)\n",
    "    if model is None or labels is None:\n",
    "        return \"Model or labels not loaded properly.\"\n",
    "    \n",
    "    img = prepare_image(img_path)\n",
    "    if img is None:\n",
    "        return \"Image not prepared properly.\"\n",
    "    \n",
    "    prediction = predict_class(model, img, labels)\n",
    "    return prediction\n",
    "\n",
    "# Example usage:\n",
    "result = classify_image('FV.h5', 'labels.json', 'Tomato.jpg')\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_people = [i for i in range(1, 501)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Groups can be if number of people are 4:, then {1, 2, 3, 4}\n",
    "# Super Set: { null, {1}, {2}, {3}, {4}, {1, 2}, {1, 3}, {1, 4}, {2, 3}, {2, 4}, {3, 4}, {1, 2, 3}, {1, 2, 4}, {1, 3, 4}, {2, 3, 4}, {1, 2, 3, 4} }\n",
    "# But groups are only {1, 2, 3, 4}, {1, 2, 3}, {1, 2, 4}, {1, 3, 4}, {2, 3, 4}, {1, 2}, {1, 3}, {1, 4}, {2, 3}, {2, 4}, {3, 4}. So count is 11\n",
    "# so\n",
    "# number of groups possible in the regular convention: 2^n - (n+1)\n",
    "number_of_groups_c = [2**i - (i+1) for i in range(1, 501)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the newly proposed method, every group can have a subset of groups as well. \n",
    "# so if { 1, 2, 3} is a subset of {1, 2, 3, 4}, then {1, 2, 3} can be have 4 subgroups. so these subgroups are added to the count. \n",
    "# The new formula would then be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def generate_subsets(s):\n",
    "    \"\"\"Generate all subsets of the given set s.\"\"\"\n",
    "    if len(s) == 0:\n",
    "        return [[]]\n",
    "    subsets = []\n",
    "    first_element = s[0]\n",
    "    for subsubset in generate_subsets(s[1:]):\n",
    "        subsets.append(subsubset)\n",
    "        next_subset = [first_element] + subsubset\n",
    "        subsets.append(next_subset)\n",
    "    return subsets\n",
    "\n",
    "def generate_unique_groups(n):\n",
    "    \"\"\"Generate all unique groups from a set of size n.\"\"\"\n",
    "    # Generate all subsets\n",
    "    all_subsets = generate_subsets(list(range(1, n+1)))\n",
    "    \n",
    "    # Remove the empty set\n",
    "    all_subsets.remove([])\n",
    "    \n",
    "    unique_groups = set()\n",
    "    \n",
    "    # For each subset, generate all non-empty subgroups and add them to the set\n",
    "    for subset in all_subsets:\n",
    "        subgroups = generate_subsets(subset)\n",
    "        subgroups.remove([])  # Remove the empty subgroup\n",
    "        # remove subgrup with 1 \n",
    "        for subgroup in subgroups:\n",
    "            if len(subgroup) == 1:\n",
    "                subgroups.remove(subgroup)\n",
    "        for subgroup in subgroups:\n",
    "            # Convert to a frozenset for immutability and add to the set of unique groups\n",
    "            unique_groups.add(frozenset(subgroup))\n",
    "    \n",
    "    #using binary search calculate the time complexity, with log(n) time complexity\n",
    "    \n",
    "    time_taken = 0\n",
    "    for i in range(1, n+1):\n",
    "        time_taken += math.log(i, 2)\n",
    "\n",
    "    return unique_groups\n",
    "\n",
    "print(len(generate_unique_groups(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_people_sample_space = [i for i in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_groups_p = [generate_unique_groups(i)[0] for i in range(1, 11)]\n",
    "time_p = [generate_unique_groups(i)[1] for i in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_groups_c = [2**i - (i+1) for i in range(1, 11)]\n",
    "time_c = [math.log(i,2) for i in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all of this into pandas dataframe\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame({'Number of People': number_people_sample_space, 'Number of Groups (Conventional)': number_of_groups_c, 'Time Taken (Conventional)': time_c, 'Net Number of Groups (Proposed)': number_of_groups_p, 'Time Taken (Proposed)': time_p})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of People</th>\n",
       "      <th>Number of Groups (Conventional)</th>\n",
       "      <th>Time Taken (Conventional)</th>\n",
       "      <th>Net Number of Groups (Proposed)</th>\n",
       "      <th>Time Taken (Proposed)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>6</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>4.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>2.321928</td>\n",
       "      <td>30</td>\n",
       "      <td>6.906891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>57</td>\n",
       "      <td>2.584963</td>\n",
       "      <td>62</td>\n",
       "      <td>9.491853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>120</td>\n",
       "      <td>2.807355</td>\n",
       "      <td>126</td>\n",
       "      <td>12.299208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>247</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>254</td>\n",
       "      <td>15.299208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>502</td>\n",
       "      <td>3.169925</td>\n",
       "      <td>510</td>\n",
       "      <td>18.469133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1013</td>\n",
       "      <td>3.321928</td>\n",
       "      <td>1022</td>\n",
       "      <td>21.791061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of People  Number of Groups (Conventional)  \\\n",
       "0                 1                                0   \n",
       "1                 2                                1   \n",
       "2                 3                                4   \n",
       "3                 4                               11   \n",
       "4                 5                               26   \n",
       "5                 6                               57   \n",
       "6                 7                              120   \n",
       "7                 8                              247   \n",
       "8                 9                              502   \n",
       "9                10                             1013   \n",
       "\n",
       "   Time Taken (Conventional)  Net Number of Groups (Proposed)  \\\n",
       "0                   0.000000                                1   \n",
       "1                   1.000000                                2   \n",
       "2                   1.584963                                6   \n",
       "3                   2.000000                               14   \n",
       "4                   2.321928                               30   \n",
       "5                   2.584963                               62   \n",
       "6                   2.807355                              126   \n",
       "7                   3.000000                              254   \n",
       "8                   3.169925                              510   \n",
       "9                   3.321928                             1022   \n",
       "\n",
       "   Time Taken (Proposed)  \n",
       "0               0.000000  \n",
       "1               1.000000  \n",
       "2               2.584963  \n",
       "3               4.584963  \n",
       "4               6.906891  \n",
       "5               9.491853  \n",
       "6              12.299208  \n",
       "7              15.299208  \n",
       "8              18.469133  \n",
       "9              21.791061  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
